---
title: "MNIST Example"
author: "Darin Stephenson"
date: "6/8/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
require("knitr")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir=normalizePath("..")) #set working directory to the project directory
library(conflicted)
library(tidyverse)
conflict_prefer("select", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("filter", "dplyr")
```

In the next block, we load the MNIST data. I adapted the show_digit function
to include the correct label.

```{r}
# modification of https://gist.github.com/brendano/39760
# automatically obtains data from the web
# creates two data frames, test and train
# labels are stored in the y variables of each data frame
# can easily train many models using formula `y ~ .` syntax

# gunzip the files
#R.utils::gunzip("train-images-idx3-ubyte.gz")
#R.utils::gunzip("train-labels-idx1-ubyte.gz")
#R.utils::gunzip("t10k-images-idx3-ubyte.gz")
#R.utils::gunzip("t10k-labels-idx1-ubyte.gz")#

# helper function for visualization
show_digit <- function(arr784, label="", col = gray(12:1 / 12), ...) {
  image(matrix(as.matrix(arr784[-785]), nrow = 28)[, 28:1], col = col, asp=1, ...)
  title(main = paste("The correct label is:",label), font.main = 4)
}

# load image files
load_image_file <- function(filename) {
  ret = list()
  f = file(filename, 'rb')
  readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  n    = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed = FALSE)
  close(f)
  data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))
}

# load label files
load_label_file <- function(filename) {
  f = file(filename, 'rb')
  readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)
  close(f)
  y
}

# load images
train <- load_image_file("train-images-idx3-ubyte")
test  <- load_image_file("t10k-images-idx3-ubyte")

# load labels
train$y <- as.factor(load_label_file("train-labels-idx1-ubyte"))
test$y  <- as.factor(load_label_file("t10k-labels-idx1-ubyte"))
```

Here's how we can display images and the correct labels.

```{r}
# view test image
i <- 1
show_digit(train[i, ],train$y[i])
```

The following code is meant to demonstrate a hyperparameter search.

```{r}
library(randomForest)
n <- 7000 # Here, n is the number of data points we are using to train.
tree_numbers <- c(700,750,800,850,900,950,1000,1050,1100)
tree_numbers2 <- c(70,75,80,85,90,95,100,105,110,115,120,125,130,135,140,145,150)
train_accuracy = c()
test_accuracy = c()
for (t in tree_numbers){
   cat("***********************", "\n")
    for (s in tree_numbers2){
         fit <- randomForest(y ~ ., data = train[1:n,],ntree=s,maxnodes=100,nodesize=10,sampsize=t, mtry=30) 
         #~89% with ntree > 70 sampsize = 1000, nodesize = 3, mtry = 28, maxnodes = 100 - downside: slow, not sure if we could make this faster? 
         #~90% with ntree=s(doesn't really differ with any value of ntree),maxnodes=100,nodesize=10,sampsize=900, mtry=28 : also slow, do I make it                faster with increasing nodesize?
         train_pred <- predict(fit,train[1:n,])
         test_pred <- predict(fit, test)
         cat("The number of trees is ", s, "\n")
         cat("The sampsize is ",t, "\n")
         cat("The training accuracy is:", mean(train_pred==train$y[1:n]), "\n")
         cat("The test accuracy is:", mean(test_pred==test$y), "\n")
         train_accuracy <- c(train_accuracy,mean(train_pred==train$y[1:n]))
         test_accuracy <- c(test_accuracy,mean(test_pred==test$y))
    }
}
```

Let's plot the training accuracy and the test accuracy together using geom_line.

```{r}
ggplot() +
  geom_line(mapping=aes(x=tree_numbers,y=train_accuracy)) +
  geom_line(mapping=aes(x=tree_numbers,y=test_accuracy)) + 
  ylim(c(0,1))
```

```{r}
incorrect <- test_pred != test$y
```

The following computes some confusion matrices for the training and test sets.

```{r confusion}
Ctrain <- matrix(0,10,10)
Ctest <- matrix(0,10,10)
for (i in 1:n){
  Ctrain[train$y[i],train_pred[i]] <- Ctrain[train$y[i],train_pred[i]] + 1  
}
for (i in 1:10000){
  Ctest[test$y[i],test_pred[i]] <- Ctest[test$y[i],test_pred[i]] + 1  
}
print(Ctrain)
print(Ctest)
print(sum(diag(Ctrain))/sum(Ctrain))
print(sum(diag(Ctest))/sum(Ctest))
```